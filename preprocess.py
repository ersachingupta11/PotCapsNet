# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aFYwed-wT4MZREfjkZ5C9mYMQ-bIIZrg
"""

!pip install helpers
import numpy as np
import torch
import matplotlib.pyplot as plt
import os
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision import datasets, transforms as T, models
import torch.nn as nn
import helpers
import torch.optim as optim
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import mean_squared_error
from sklearn.metrics import matthews_corrcoef
from sklearn.manifold import TSNE

torch.cuda.empty_cache()
seed = 1
np.random.seed(seed)
torch.manual_seed(seed)

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

os.listdir('/content/drive/MyDrive/Potato')

train_path= '/content/drive/MyDrive/Potato/Train'
val_path= '/content/drive/MyDrive/Potato/Valid'
test_path= '/content/drive/MyDrive/Potato/Test'

from collections import Counter

# Get a list of all class labels in the test directory
class_labels = os.listdir(train_path)

# Count the number of images per class
image_counts = Counter()

for label in class_labels:
    class_path = os.path.join(train_path, label)
    image_count = len(os.listdir(class_path))
    image_counts[label] = image_count

# Print the number of images per class
for label, count in image_counts.items():
    print("Class:", label, "Number of images:", count)

train_transforms = T.Compose([T.Resize((224,224)), T.ToTensor()])
valid_transforms = T.Compose([T.Resize((224,224)), T.ToTensor()])
test_transforms = T.Compose([T.Resize((224,224)), T.ToTensor()])

train_data = datasets.ImageFolder(train_path, transform=train_transforms)
valid_data = datasets.ImageFolder(val_path, transform=valid_transforms)
test_data = datasets.ImageFolder(test_path, transform=test_transforms)
trainloader = DataLoader(train_data, batch_size=10,shuffle=True)
validloader = DataLoader(valid_data, batch_size=10, shuffle=True)
testloader = DataLoader(test_data, batch_size=10, shuffle=True)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

batch_size=10
dataiter = iter(trainloader)
images, labels = next(dataiter)
images = images.numpy()

fig = plt.figure(figsize=(25, 4))
for idx in np.arange(batch_size):
    ax = fig.add_subplot(2, int(batch_size/2), idx+1, xticks=[], yticks=[])
    ax.imshow(np.squeeze(images[idx].T), cmap='gray')
    # print out the correct label for each image
    # .item() gets the value contained in a Tensor
    ax.set_title(str(labels[idx].item()))